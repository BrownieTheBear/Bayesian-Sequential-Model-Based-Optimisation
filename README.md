# Bayesian-Sequential-Model-Based-Optimisation

Hyperparameter optimisation is the process of choosing a set of optimal hyperparameters for a machine learning algorithm. Hyperparameters are parameters given that control the learning process during the training phase. This paper examines and visualises the tuning process across 3 major optimisation regimes; Grid Search, Random Search & Bayesian Sequential Model Based Optimisation methods. Experimental results show that there are significant computational advantages to using a probabilistic approach to cover high dimensional Euclidean search spaces as opposed to uninformed strategies. Mathematical primers for all relevant statistical material are included. 

The full Jupyter Notebook code can be found at https://github.com/MBStudent1/FinalProject/blob/master/SMBO%20Parameter%20Optimisation%20Python%20Notebook.ipynb
